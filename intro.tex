\section{Introduction}
\par An optimization algorithm is a way to maximize or minimize results that would involve one or multiple parameters. For an optimization algorithm to work, it would need a fitness function. A fitness function is a way to define an optimization problem. It takes in the currently worked on solution and describes how good, efficient or optimal that solution is to the problem. After describing those solutions, the algorithm also picks out new solutions and then repeats the process for those solutions until it stops on condition.

\par Take for an example scheduling jobs for people of different skills. It can be said that different people excels in a job more than others because of their skill and the better they are, the more efficient they work. So, it is imperative that a manager recognize those skills and assign the jobs correctly according to those skills. An optimization algorithm with the right parameters can assign jobs to everyone such that the different skills of people can be best utilized. Being an algorithm not only for Job Scheduling, optimization algorithm can also be used to solve various problems such as data clustering, pattern recognition, tuning of neural networks and so much more.

\par There are two ways to solve an optimization problem. One way is through using the fitness function's derivative. Upon finding the parameters that make the function's derivative equal to zero, the maximized or minimized solution is found. The first way to solve an optimization problem is derivative-based optimization. Second, another way to solve an optimization problem is described by not knowing what the derivative of the fitness function is. This is done by testing each random solution and informedly picking new ones, which could be called as the way of derivative-free optimization (or black-box optimization).

\subsection{Lion Optimization Algorithm}

\par The optimization algorithm that is tackled on in this paper is called the `Lion Optimization Algorithm'. It is an algorithm inspired by the lifestyle of lions including prides and nomads. While this is also done by the Lion's Algorithm and the Lion Pride Optimizer, the algorithm brings all of the techniques found in the mentioned algorithms all together. The main feature of the Lion Optimization Algorithm is its degree of adaptability tightly coupled on the parameters used. Depending on the fitness function and parameters used, it could find a sweet spot in between to have better performance than other algorithms. An improvement is made to extend the functionality of the Optimization Algorithm. The improvement utilizes more information that is generated within the algorithm to further improve on its functionality.

\subsection{No Free Lunch Theorems}
\par Since there are already so many optimization algorithms, what's the point of making a new one? The No Free Lunch Theorems were introduced in 1997 by Wolpert and Macready to address the need for newer optimization algorithms. The first of their theorems states that for any pair of algorithms $a_1$ and $a_2$, iterated $m$ times, $$ \sum_{f} P(d_{m}^{y}|f,m,a_1)=\sum_{f} P(d_{m}^{y}|f,m,a_2),$$ where $d_m^y$ denotes the set of size $m$ of the cost values $y\in Y$ associated to the input values $x\in X,f:X\to Y$ is the function being optimized and $P(d_m^y|f,m,a)$ is the conditional probability of obtaining a given sequence of cost values from algorithm $a$ run $m$ times on function $f$. Essentially, this says that when all functions $f$ are equally likely to be used, the probability of observing an arbitrary sequence of cost values over the course of optimization is independent of the algorithm.

\par This theorem indicates that if an algorithm performs better than another algorithm on some class of problems, then it must perform worse on the remaining problems. Consequently, this implies that there is no general-purpose optimization algorithm that is universally superior than the rest. Hence, the development of newer optimization algorithms is still needed.

\par While the algorithm is an extension to Lion Optimization Algorithm, the new algorithm may work better in some functions than the original all the while performing worse on others. The new algorithm can also be adjusted in such a way that the algorithm works like the original Lion Optimization Algorithm.

\section{Improvements}

\par This is a research of a multi-part improvement to the Lion Optimization Algorithm. The improvement is done across multiple sections of the algorithm to improve the overall performance of every run. Most of this improvements are also modeled heuristically after lions, their influence to another, their nature and broadly, evolution in general. While the Lion Optimization Algorithm includes ways to slightly modify its behavior, there are still rooms for improvement for the algorithm which will be talked about in the next sections.
